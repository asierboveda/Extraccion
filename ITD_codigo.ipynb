{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c892466",
   "metadata": {},
   "source": [
    "### ITD\n",
    "En este dataset tenemos fotos tomadas con 10 c√°maras diferentes a diferentes telas. De cada c√°mara tenemos una parte de las fotos para train, en las que solamente hay fotos de telas en buen estado. Y otra parte para test, en las que hay fotos de telas en buen estado y da√±adas.\n",
    "El objetivo es entrenar el modelo solo con las fotos de train (tela en buen estado) y poder predecir si una foto de test es una tela en buen estado ($y_{test}=0$) o da√±ada ($y_{test}=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc72b7a",
   "metadata": {},
   "source": [
    "## Leer datos todos juntos\n",
    "\n",
    "Leemos mezclando test y train, y luego particioanremos todos los datos en train, val y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fecc6f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Escaneando im√°genes en: c:\\Users\\ander\\OneDrive - UPNA\\4¬∫\\Extracci√≥n del conocimiento\\TrabajoGrupo\\ITD ...\n",
      "‚úÖ Carga completa. 5878 im√°genes procesadas.\n",
      "\n",
      "Forma de X_total: (5878, 64, 64)\n",
      "------------------------------\n",
      "üîπ Train shape: (4114, 64, 64) (Listo para Autoencoders/CNN)\n",
      "üîπ Val shape:   (882, 64, 64)\n",
      "üîπ Test shape:  (882, 64, 64)\n",
      "------------------------------\n",
      "Train anomalies: 675\n",
      "Val anomalies:   145\n",
      "Test anomalies:  145\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cargar_dataset_imagenes(root_path, image_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Lee las im√°genes y las devuelve en formato (N, Alto, Ancho).\n",
    "    NO aplana las im√°genes. Mantiene la estructura espacial.\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    root = Path(root_path)\n",
    "    print(f\"üìÇ Escaneando im√°genes en: {root.absolute()} ...\")\n",
    "    \n",
    "    if not root.exists():\n",
    "        print(\"‚ùå Error: La ruta no existe.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    contador = 0\n",
    "    \n",
    "    for img_path in root.rglob('*.*'):\n",
    "        if img_path.suffix.lower() not in ['.png', '.jpg', '.jpeg', '.bmp']:\n",
    "            continue\n",
    "            \n",
    "        # --- 1. ETIQUETADO ---\n",
    "        # 1 = Defecto (Anomaly), 0 = Bien (Good)\n",
    "        label = 1 if 'anomaly' in str(img_path).lower() else 0\n",
    "            \n",
    "        # --- 2. LECTURA (Escala de Grises) ---\n",
    "        # Leemos en blanco y negro para simplificar (1 canal). \n",
    "        # Si quisieras color, quita el flag IMREAD_GRAYSCALE.\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None: continue\n",
    "        \n",
    "        # --- 3. RESIZE (Obligatorio) ---\n",
    "        # Todas deben medir lo mismo para entrar en el array numpy\n",
    "        img = cv2.resize(img, image_size)\n",
    "        \n",
    "        # --- 4. NORMALIZACI√ìN ---\n",
    "        # Pasamos de 0-255 (enteros) a 0.0-1.0 (float).\n",
    "        # Esto es vital tanto para ML cl√°sico como para Deep Learning.\n",
    "        img_norm = img.astype('float32') / 255.0\n",
    "        \n",
    "        X_list.append(img_norm)\n",
    "        y_list.append(label)\n",
    "        contador += 1\n",
    "\n",
    "    # Convertimos la lista a un Array Numpy 3D: (N_fotos, Alto, Ancho)\n",
    "    X_array = np.array(X_list)\n",
    "    y_array = np.array(y_list)\n",
    "\n",
    "    print(f\"‚úÖ Carga completa. {contador} im√°genes procesadas.\")\n",
    "    return X_array, y_array\n",
    "\n",
    "# --- EJECUCI√ìN: CARGAR Y DIVIDIR ---\n",
    "\n",
    "ruta = \"./ITD\" # Tu ruta\n",
    "X_total, y_total = cargar_dataset_imagenes(ruta, image_size=(64, 64))\n",
    "\n",
    "# Verificaci√≥n de forma\n",
    "# Deber√≠a salir algo como: (5000, 64, 64) -> 5000 fotos de 64x64\n",
    "print(f\"\\nForma de X_total: {X_total.shape}\") \n",
    "\n",
    "# --- PARTICI√ìN (Train / Val / Test) ---\n",
    "# 1. Separamos Train (70%) del resto (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_total, y_total, test_size=0.3, random_state=42, stratify=y_total\n",
    ")\n",
    "\n",
    "# 2. Separamos el resto en Val (15%) y Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"üîπ Train shape: {X_train.shape} (Listo para Autoencoders/CNN)\")\n",
    "print(f\"üîπ Val shape:   {X_val.shape}\")\n",
    "print(f\"üîπ Test shape:  {X_test.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# mostramos numero de anomalias en cada conjunto\n",
    "print(f\"Train anomalies: {np.sum(y_train)}\")\n",
    "print(f\"Val anomalies:   {np.sum(y_val)}\")\n",
    "print(f\"Test anomalies:  {np.sum(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86362f16",
   "metadata": {},
   "source": [
    "Ahora la forma de leerlos de train (solo good) y test (good y anomaly) por separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def cargar_datos_separados_raw(root_path, image_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Lee las carpetas originales 'train' y 'test' y devuelve los datos separados.\n",
    "    Formato: RAW (P√≠xeles 2D, normalizados 0-1).\n",
    "    \"\"\"\n",
    "    # Listas para Entrenamiento\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    # Listas para Test\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    root = Path(root_path)\n",
    "    print(f\"üìÇ Escaneando estructura original en: {root.absolute()} ...\")\n",
    "    \n",
    "    if not root.exists():\n",
    "        print(\"‚ùå Error: La ruta no existe.\")\n",
    "        return np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    contador_train = 0\n",
    "    contador_test = 0\n",
    "    \n",
    "    for img_path in root.rglob('*.*'):\n",
    "        if img_path.suffix.lower() not in ['.png', '.jpg', '.jpeg', '.bmp']:\n",
    "            continue\n",
    "        \n",
    "        path_str = str(img_path).lower()\n",
    "        \n",
    "        # --- 1. IDENTIFICAR SPLIT (¬øEs Train o Test?) ---\n",
    "        if 'train' in path_str:\n",
    "            is_train = True\n",
    "        elif 'test' in path_str:\n",
    "            is_train = False\n",
    "        else:\n",
    "            continue # Si no est√° en ninguna carpeta train/test, la ignoramos\n",
    "            \n",
    "        # --- 2. IDENTIFICAR ETIQUETA (¬øGood o Anomaly?) ---\n",
    "        # 1 = Defecto, 0 = Bien\n",
    "        label = 1 if 'anomaly' in path_str else 0\n",
    "        \n",
    "        # --- 3. LEER RAW (Escala de Grises) ---\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None: continue\n",
    "        \n",
    "        # --- 4. RESIZE & NORMALIZACI√ìN ---\n",
    "        img = cv2.resize(img, image_size)\n",
    "        img_norm = img.astype('float32') / 255.0\n",
    "        \n",
    "        # --- 5. GUARDAR DONDE TOQUE ---\n",
    "        if is_train:\n",
    "            X_train.append(img_norm)\n",
    "            y_train.append(label)\n",
    "            contador_train += 1\n",
    "        else:\n",
    "            X_test.append(img_norm)\n",
    "            y_test.append(label)\n",
    "            contador_test += 1\n",
    "\n",
    "    # Convertir todo a Numpy Arrays\n",
    "    X_train_arr = np.array(X_train)\n",
    "    y_train_arr = np.array(y_train)\n",
    "    X_test_arr = np.array(X_test)\n",
    "    y_test_arr = np.array(y_test)\n",
    "\n",
    "    print(f\"‚úÖ Carga finalizada.\")\n",
    "    print(f\"   Train: {contador_train} im√°genes.\")\n",
    "    print(f\"   Test:  {contador_test} im√°genes.\")\n",
    "    \n",
    "    return X_train_arr, y_train_arr, X_test_arr, y_test_arr\n",
    "\n",
    "# --- USO ---\n",
    "ruta = \"./ITD\" # Aseg√∫rate que es la ruta correcta\n",
    "X_train, y_train, X_test, y_test = cargar_datos_separados_raw(ruta, image_size=(64, 64))\n",
    "\n",
    "print(\"\\n--- DIMENSIONES (RAW) ---\")\n",
    "# Deber√≠a salir (N, 64, 64) -> Datos 2D listos para lo que quieras\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "print(f\"y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo r√°pido para Isolation Forest\n",
    "# -1 le dice a numpy: \"calcula t√∫ esta dimensi√≥n\" (que ser√° 64*64 = 4096)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1) \n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(f\"Forma aplanada para ML Cl√°sico: {X_train_flat.shape}\") \n",
    "# Resultado: (N, 4096)\n",
    "\n",
    "# clf.fit(X_train_flat) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo mental para futuro (PyTorch)\n",
    "# Solo tendr√≠as que a√±adir una dimensi√≥n de canal: (N, 1, 64, 64)\n",
    "# tensor_img = torch.from_numpy(X_train).unsqueeze(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
